{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAnKgif_XsPH",
        "outputId": "aba1d7b1-995a-4d55-f372-c1c02e9aa528"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install filterpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pV7p4RzWYG-u",
        "outputId": "0dc8d092-dbfa-4cb3-9c73-625ad5505c43"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting filterpy\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[K     |████████████████████████████████| 177 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from filterpy) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from filterpy) (1.7.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from filterpy) (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->filterpy) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->filterpy) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->filterpy) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->filterpy) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->filterpy) (1.15.0)\n",
            "Building wheels for collected packages: filterpy\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110474 sha256=4c686f089ecb3b4f76ff486d71a75c26c7f5b9ff76aeaa112ba8eb29bd5a055f\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/f6/cb/40331472edf4fd399b8cad02973c6acbdf26898342928327fe\n",
            "Successfully built filterpy\n",
            "Installing collected packages: filterpy\n",
            "Successfully installed filterpy-1.4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FhHNuiQhrbYQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "604c9f83-236a-4b63-def9-2c4b40d5f0af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Autogluon\n",
            "  Downloading autogluon-0.6.1-py3-none-any.whl (9.8 kB)\n",
            "Collecting autogluon.multimodal==0.6.1\n",
            "  Downloading autogluon.multimodal-0.6.1-py3-none-any.whl (289 kB)\n",
            "\u001b[K     |████████████████████████████████| 289 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting autogluon.vision==0.6.1\n",
            "  Downloading autogluon.vision-0.6.1-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 834 kB/s \n",
            "\u001b[?25hCollecting autogluon.text==0.6.1\n",
            "  Downloading autogluon.text-0.6.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 54 kB/s \n",
            "\u001b[?25hCollecting autogluon.tabular[all]==0.6.1\n",
            "  Downloading autogluon.tabular-0.6.1-py3-none-any.whl (286 kB)\n",
            "\u001b[K     |████████████████████████████████| 286 kB 18.7 MB/s \n",
            "\u001b[?25hCollecting autogluon.core[all]==0.6.1\n",
            "  Downloading autogluon.core-0.6.1-py3-none-any.whl (226 kB)\n",
            "\u001b[K     |████████████████████████████████| 226 kB 54.5 MB/s \n",
            "\u001b[?25hCollecting autogluon.features==0.6.1\n",
            "  Downloading autogluon.features-0.6.1-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 1.2 MB/s \n",
            "\u001b[?25hCollecting autogluon.timeseries[all]==0.6.1\n",
            "  Downloading autogluon.timeseries-0.6.1-py3-none-any.whl (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from autogluon.core[all]==0.6.1->Autogluon) (3.2.2)\n",
            "Requirement already satisfied: numpy<1.24,>=1.21 in /usr/local/lib/python3.8/dist-packages (from autogluon.core[all]==0.6.1->Autogluon) (1.21.6)\n",
            "Requirement already satisfied: pandas!=1.4.0,<1.6,>=1.2.5 in /usr/local/lib/python3.8/dist-packages (from autogluon.core[all]==0.6.1->Autogluon) (1.3.5)\n",
            "Collecting autogluon.common==0.6.1\n",
            "  Downloading autogluon.common-0.6.1-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 95 kB/s \n",
            "\u001b[?25hCollecting dask<=2021.11.2,>=2021.09.1\n",
            "  Downloading dask-2021.11.2-py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 39.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from autogluon.core[all]==0.6.1->Autogluon) (4.64.1)\n",
            "Collecting distributed<=2021.11.2,>=2021.09.1\n",
            "  Downloading distributed-2021.11.2-py3-none-any.whl (802 kB)\n",
            "\u001b[K     |████████████████████████████████| 802 kB 45.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy<1.10.0,>=1.5.4 in /usr/local/lib/python3.8/dist-packages (from autogluon.core[all]==0.6.1->Autogluon) (1.7.3)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.29-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 50.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn<1.2,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from autogluon.core[all]==0.6.1->Autogluon) (1.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from autogluon.core[all]==0.6.1->Autogluon) (2.23.0)\n",
            "Collecting ray[tune]<2.1,>=2.0\n",
            "  Downloading ray-2.0.1-cp38-cp38-manylinux2014_x86_64.whl (60.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 60.2 MB 1.1 MB/s \n",
            "\u001b[?25hCollecting hyperopt<0.2.8,>=0.2.7\n",
            "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 58.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from autogluon.common==0.6.1->autogluon.core[all]==0.6.1->Autogluon) (57.4.0)\n",
            "Collecting psutil<6,>=5.7.3\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[K     |████████████████████████████████| 280 kB 49.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: text-unidecode<=1.3 in /usr/local/lib/python3.8/dist-packages (from autogluon.multimodal==0.6.1->Autogluon) (1.3)\n",
            "Collecting omegaconf<2.2.0,>=2.1.1\n",
            "  Downloading omegaconf-2.1.2-py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 3.8 MB/s \n",
            "\u001b[?25hCollecting seqeval<=1.2.2\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting scikit-image<0.20.0,>=0.19.1\n",
            "  Downloading scikit_image-0.19.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.0 MB 48.0 MB/s \n",
            "\u001b[?25hCollecting timm<0.7.0\n",
            "  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n",
            "\u001b[K     |████████████████████████████████| 549 kB 55.9 MB/s \n",
            "\u001b[?25hCollecting accelerate<0.14,>=0.9\n",
            "  Downloading accelerate-0.13.2-py3-none-any.whl (148 kB)\n",
            "\u001b[K     |████████████████████████████████| 148 kB 65.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk<4.0.0,>=3.4.5 in /usr/local/lib/python3.8/dist-packages (from autogluon.multimodal==0.6.1->Autogluon) (3.7)\n",
            "Collecting torchtext<0.14.0\n",
            "  Downloading torchtext-0.13.1-cp38-cp38-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 52.0 MB/s \n",
            "\u001b[?25hCollecting torchmetrics<0.9.0,>=0.8.0\n",
            "  Downloading torchmetrics-0.8.2-py3-none-any.whl (409 kB)\n",
            "\u001b[K     |████████████████████████████████| 409 kB 76.8 MB/s \n",
            "\u001b[?25hCollecting torch<1.13,>=1.9\n",
            "  Downloading torch-1.12.1-cp38-cp38-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.3 MB 1.3 kB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema<=4.8.0 in /usr/local/lib/python3.8/dist-packages (from autogluon.multimodal==0.6.1->Autogluon) (4.3.3)\n",
            "Collecting pytorch-metric-learning<1.4.0,>=1.3.0\n",
            "  Downloading pytorch_metric_learning-1.3.2-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 63.0 MB/s \n",
            "\u001b[?25hCollecting pytorch-lightning<1.8.0,>=1.7.4\n",
            "  Downloading pytorch_lightning-1.7.7-py3-none-any.whl (708 kB)\n",
            "\u001b[K     |████████████████████████████████| 708 kB 58.8 MB/s \n",
            "\u001b[?25hCollecting sentencepiece<0.2.0,>=0.1.95\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 58.3 MB/s \n",
            "\u001b[?25hCollecting nptyping<1.5.0,>=1.4.4\n",
            "  Downloading nptyping-1.4.4-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: defusedxml<=0.7.1,>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from autogluon.multimodal==0.6.1->Autogluon) (0.7.1)\n",
            "Collecting fairscale<=0.4.6,>=0.4.5\n",
            "  Downloading fairscale-0.4.6.tar.gz (248 kB)\n",
            "\u001b[K     |████████████████████████████████| 248 kB 62.3 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: smart-open<5.3.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from autogluon.multimodal==0.6.1->Autogluon) (5.2.1)\n",
            "Collecting Pillow<=9.4.0,>=9.3.0\n",
            "  Downloading Pillow-9.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 53.8 MB/s \n",
            "\u001b[?25hCollecting torchvision<0.14.0\n",
            "  Downloading torchvision-0.13.1-cp38-cp38-manylinux1_x86_64.whl (19.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.1 MB 23 kB/s \n",
            "\u001b[?25hCollecting nlpaug<=1.1.10,>=1.1.10\n",
            "  Downloading nlpaug-1.1.10-py3-none-any.whl (410 kB)\n",
            "\u001b[K     |████████████████████████████████| 410 kB 74.9 MB/s \n",
            "\u001b[?25hCollecting albumentations<=1.2.0,>=1.1.0\n",
            "  Downloading albumentations-1.2.0-py3-none-any.whl (113 kB)\n",
            "\u001b[K     |████████████████████████████████| 113 kB 79.7 MB/s \n",
            "\u001b[?25hCollecting evaluate<=0.3.0\n",
            "  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting openmim<=0.2.1,>0.1.5\n",
            "  Downloading openmim-0.2.1-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.4 MB/s \n",
            "\u001b[?25hCollecting transformers<4.24.0,>=4.23.0\n",
            "  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.3 MB 42.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx<3.0,>=2.3 in /usr/local/lib/python3.8/dist-packages (from autogluon.tabular[all]==0.6.1->Autogluon) (2.8.8)\n",
            "Requirement already satisfied: fastai<2.8,>=2.3.1 in /usr/local/lib/python3.8/dist-packages (from autogluon.tabular[all]==0.6.1->Autogluon) (2.7.10)\n",
            "Collecting lightgbm<3.4,>=3.3\n",
            "  Downloading lightgbm-3.3.3-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 75.8 MB/s \n",
            "\u001b[?25hCollecting xgboost<1.8,>=1.6\n",
            "  Downloading xgboost-1.7.2-py3-none-manylinux2014_x86_64.whl (193.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 193.6 MB 74 kB/s \n",
            "\u001b[?25hCollecting catboost<1.2,>=1.0\n",
            "  Downloading catboost-1.1.1-cp38-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.6 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting psutil<6,>=5.7.3\n",
            "  Downloading psutil-5.8.0-cp38-cp38-manylinux2010_x86_64.whl (296 kB)\n",
            "\u001b[K     |████████████████████████████████| 296 kB 48.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib~=1.1 in /usr/local/lib/python3.8/dist-packages (from autogluon.timeseries[all]==0.6.1->Autogluon) (1.2.0)\n",
            "Collecting statsmodels~=0.13.0\n",
            "  Downloading statsmodels-0.13.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 58.3 MB/s \n",
            "\u001b[?25hCollecting gluonts~=0.11.0\n",
            "  Downloading gluonts-0.11.5-py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 62.7 MB/s \n",
            "\u001b[?25hCollecting sktime<0.14,>=0.13.1\n",
            "  Downloading sktime-0.13.4-py3-none-any.whl (7.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0 MB 63.1 MB/s \n",
            "\u001b[?25hCollecting pmdarima~=1.8.2\n",
            "  Downloading pmdarima-1.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 65.6 MB/s \n",
            "\u001b[?25hCollecting tbats~=1.1\n",
            "  Downloading tbats-1.1.2-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.5 MB/s \n",
            "\u001b[?25hCollecting gluoncv<0.10.6,>=0.10.5\n",
            "  Downloading gluoncv-0.10.5.post0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 71.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from accelerate<0.14,>=0.9->autogluon.multimodal==0.6.1->Autogluon) (21.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from accelerate<0.14,>=0.9->autogluon.multimodal==0.6.1->Autogluon) (6.0)\n",
            "Collecting albumentations<=1.2.0,>=1.1.0\n",
            "  Downloading albumentations-1.1.0-py3-none-any.whl (102 kB)\n",
            "\u001b[K     |████████████████████████████████| 102 kB 62.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from albumentations<=1.2.0,>=1.1.0->autogluon.multimodal==0.6.1->Autogluon) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from albumentations<=1.2.0,>=1.1.0->autogluon.multimodal==0.6.1->Autogluon) (4.6.0.66)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from catboost<1.2,>=1.0->autogluon.tabular[all]==0.6.1->Autogluon) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.8/dist-packages (from catboost<1.2,>=1.0->autogluon.tabular[all]==0.6.1->Autogluon) (0.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.8/dist-packages (from catboost<1.2,>=1.0->autogluon.tabular[all]==0.6.1->Autogluon) (5.5.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.8/dist-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->Autogluon) (0.12.0)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->Autogluon) (1.5.0)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.8/dist-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->Autogluon) (1.3.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->Autogluon) (2022.11.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->Autogluon) (1.0.4)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.8/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->Autogluon) (2.2.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->Autogluon) (1.7.0)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.8/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->Autogluon) (2.4.0)\n",
            "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.8/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->Autogluon) (6.0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->Autogluon) (2.11.3)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.8/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->Autogluon) (7.1.2)\n",
            "Collecting datasets>=2.0.0\n",
            "  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 64.8 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.7.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 61.8 MB/s \n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 77.6 MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 81.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from evaluate<=0.3.0->autogluon.multimodal==0.6.1->Autogluon) (0.3.6)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate<=0.3.0->autogluon.multimodal==0.6.1->Autogluon) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate<=0.3.0->autogluon.multimodal==0.6.1->Autogluon) (3.8.3)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.8/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->Autogluon) (1.0.3)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->Autogluon) (21.1.3)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.8/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->Autogluon) (3.4.3)\n",
            "Requirement already satisfied: fastcore<1.6,>=1.4.5 in /usr/local/lib/python3.8/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->Autogluon) (1.5.27)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.8/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->Autogluon) (0.0.7)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate<=0.3.0->autogluon.multimodal==0.6.1->Autogluon) (22.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate<=0.3.0->autogluon.multimodal==0.6.1->Autogluon) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate<=0.3.0->autogluon.multimodal==0.6.1->Autogluon) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate<=0.3.0->autogluon.multimodal==0.6.1->Autogluon) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate<=0.3.0->autogluon.multimodal==0.6.1->Autogluon) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate<=0.3.0->autogluon.multimodal==0.6.1->Autogluon) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate<=0.3.0->autogluon.multimodal==0.6.1->Autogluon) (6.0.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from gluoncv<0.10.6,>=0.10.5->autogluon.vision==0.6.1->Autogluon) (4.6.0.66)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting autocfg\n",
            "  Downloading autocfg-0.0.8-py3-none-any.whl (13 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.8/dist-packages (from gluonts~=0.11.0->autogluon.timeseries[all]==0.6.1->Autogluon) (4.4.0)\n",
            "Requirement already satisfied: pydantic~=1.7 in /usr/local/lib/python3.8/dist-packages (from gluonts~=0.11.0->autogluon.timeseries[all]==0.6.1->Autogluon) (1.10.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate<=0.3.0->autogluon.multimodal==0.6.1->Autogluon) (3.8.0)\n",
            "Collecting py4j\n",
            "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[K     |████████████████████████████████| 200 kB 49.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.6.1->Autogluon) (0.16.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema<=4.8.0->autogluon.multimodal==0.6.1->Autogluon) (5.10.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema<=4.8.0->autogluon.multimodal==0.6.1->Autogluon) (0.19.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema<=4.8.0->autogluon.multimodal==0.6.1->Autogluon) (3.11.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from lightgbm<3.4,>=3.3->autogluon.tabular[all]==0.6.1->Autogluon) (0.38.4)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==0.6.1->Autogluon) (2022.6.2)\n",
            "Collecting typish>=1.7.0\n",
            "  Downloading typish-1.9.3-py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 79.7 MB/s \n",
            "\u001b[?25hCollecting rich\n",
            "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
            "\u001b[K     |████████████████████████████████| 237 kB 74.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from openmim<=0.2.1,>0.1.5->autogluon.multimodal==0.6.1->Autogluon) (0.8.10)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting model-index\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->accelerate<0.14,>=0.9->autogluon.multimodal==0.6.1->Autogluon) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas!=1.4.0,<1.6,>=1.2.5->autogluon.core[all]==0.6.1->Autogluon) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas!=1.4.0,<1.6,>=1.2.5->autogluon.core[all]==0.6.1->Autogluon) (2022.6)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.8/dist-packages (from partd>=0.3.10->dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->Autogluon) (1.0.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from pmdarima~=1.8.2->autogluon.timeseries[all]==0.6.1->Autogluon) (1.24.3)\n",
            "Requirement already satisfied: Cython!=0.29.18,>=0.29 in /usr/local/lib/python3.8/dist-packages (from pmdarima~=1.8.2->autogluon.timeseries[all]==0.6.1->Autogluon) (0.29.32)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->Autogluon) (2.9.1)\n",
            "Collecting pyDeprecate>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.15.3 in /usr/local/lib/python3.8/dist-packages (from ray[tune]<2.1,>=2.0->autogluon.core[all]==0.6.1->Autogluon) (3.19.6)\n",
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.17.1-py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 54.3 MB/s \n",
            "\u001b[?25hCollecting grpcio<=1.43.0,>=1.32.0\n",
            "  Downloading grpcio-1.43.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 46.8 MB/s \n",
            "\u001b[?25hCollecting tensorboardX>=1.9\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 55.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->autogluon.core[all]==0.6.1->Autogluon) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->autogluon.core[all]==0.6.1->Autogluon) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->autogluon.core[all]==0.6.1->Autogluon) (2022.9.24)\n",
            "Collecting urllib3\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 60.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.6.1->Autogluon) (1.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.6.1->Autogluon) (2022.10.10)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.6.1->Autogluon) (2.9.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<1.2,>=1.0.0->autogluon.core[all]==0.6.1->Autogluon) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.8/dist-packages (from sktime<0.14,>=0.13.1->autogluon.timeseries[all]==0.6.1->Autogluon) (0.56.4)\n",
            "Collecting deprecated>=1.2.13\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.8/dist-packages (from deprecated>=1.2.13->sktime<0.14,>=0.13.1->autogluon.timeseries[all]==0.6.1->Autogluon) (1.14.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.53->sktime<0.14,>=0.13.1->autogluon.timeseries[all]==0.6.1->Autogluon) (0.39.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.53->sktime<0.14,>=0.13.1->autogluon.timeseries[all]==0.6.1->Autogluon) (4.13.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->Autogluon) (0.10.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->Autogluon) (3.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->Autogluon) (2.0.7)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->Autogluon) (1.0.3)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->Autogluon) (0.7.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->Autogluon) (3.3.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->Autogluon) (0.10.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->Autogluon) (3.0.8)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->Autogluon) (2.4.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->Autogluon) (1.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->Autogluon) (8.1.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->Autogluon) (2.0.8)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.8/dist-packages (from statsmodels~=0.13.0->autogluon.timeseries[all]==0.6.1->Autogluon) (0.5.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->Autogluon) (1.3.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->Autogluon) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->Autogluon) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->Autogluon) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->Autogluon) (2.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->Autogluon) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->Autogluon) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->Autogluon) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->Autogluon) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->Autogluon) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->Autogluon) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->Autogluon) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->Autogluon) (3.2.2)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->Autogluon) (0.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->Autogluon) (0.7.9)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 48.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: heapdict in /usr/local/lib/python3.8/dist-packages (from zict>=0.1.3->distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->Autogluon) (1.0.1)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.8 MB/s \n",
            "\u001b[?25hCollecting botocore<1.30.0,>=1.29.29\n",
            "  Downloading botocore-1.29.29-py3-none-any.whl (10.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.3 MB 55.1 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->Autogluon) (2.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->autogluon.core[all]==0.6.1->Autogluon) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->autogluon.core[all]==0.6.1->Autogluon) (0.11.0)\n",
            "Collecting ordered-set\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly->catboost<1.2,>=1.0->autogluon.tabular[all]==0.6.1->Autogluon) (8.1.0)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.8/dist-packages (from rich->openmim<=0.2.1,>0.1.5->autogluon.multimodal==0.6.1->Autogluon) (2.6.1)\n",
            "Collecting distlib<1,>=0.3.6\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[K     |████████████████████████████████| 468 kB 56.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: platformdirs<3,>=2.4 in /usr/local/lib/python3.8/dist-packages (from virtualenv->ray[tune]<2.1,>=2.0->autogluon.core[all]==0.6.1->Autogluon) (2.5.4)\n",
            "Building wheels for collected packages: fairscale, antlr4-python3-runtime, seqeval\n",
            "  Building wheel for fairscale (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.6-py3-none-any.whl size=307251 sha256=f78b5451af9b1e16b62e67e73aea6345d1aa335a39a7f9cbc45699e9f7791936\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/4c/a4/f6c0eec2ec5c8ffca075e62b0329801f862e1f1b71422f456b\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141231 sha256=4e8ed7e5faaca708f88f7cc42a27a17cdd61cfc4c1c011f1484b0dea570ab5d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/d0/ab/d43c02eaddc5b9004db86950802442ad9a26f279c619e28da0\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=88a1cd1aeca3fbf9903e305a040e7f875703f48d7aceecc36994355b2d0ecc05\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
            "Successfully built fairscale antlr4-python3-runtime seqeval\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, psutil, distlib, dask, boto3, virtualenv, Pillow, grpcio, distributed, autogluon.common, xxhash, torch, tensorboardX, responses, ray, pyDeprecate, py4j, ordered-set, multiprocess, huggingface-hub, commonmark, autogluon.features, autogluon.core, xgboost, typish, torchvision, torchmetrics, tokenizers, statsmodels, scikit-image, rich, model-index, lightgbm, hyperopt, datasets, colorama, catboost, autogluon.tabular, antlr4-python3-runtime, yacs, transformers, torchtext, timm, seqeval, sentencepiece, pytorch-metric-learning, pytorch-lightning, portalocker, pmdarima, openmim, omegaconf, nptyping, nlpaug, gluonts, fairscale, evaluate, deprecated, autocfg, albumentations, accelerate, tbats, sktime, gluoncv, autogluon.timeseries, autogluon.multimodal, autogluon.vision, autogluon.text, Autogluon\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2022.2.1\n",
            "    Uninstalling dask-2022.2.1:\n",
            "      Successfully uninstalled dask-2022.2.1\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.51.1\n",
            "    Uninstalling grpcio-1.51.1:\n",
            "      Successfully uninstalled grpcio-1.51.1\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 2022.2.1\n",
            "    Uninstalling distributed-2022.2.1:\n",
            "      Successfully uninstalled distributed-2022.2.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.0+cu116\n",
            "    Uninstalling torch-1.13.0+cu116:\n",
            "      Successfully uninstalled torch-1.13.0+cu116\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.0+cu116\n",
            "    Uninstalling torchvision-0.14.0+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.0+cu116\n",
            "  Attempting uninstall: statsmodels\n",
            "    Found existing installation: statsmodels 0.12.2\n",
            "    Uninstalling statsmodels-0.12.2:\n",
            "      Successfully uninstalled statsmodels-0.12.2\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.18.3\n",
            "    Uninstalling scikit-image-0.18.3:\n",
            "      Successfully uninstalled scikit-image-0.18.3\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "  Attempting uninstall: hyperopt\n",
            "    Found existing installation: hyperopt 0.1.2\n",
            "    Uninstalling hyperopt-0.1.2:\n",
            "      Successfully uninstalled hyperopt-0.1.2\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.14.0\n",
            "    Uninstalling torchtext-0.14.0:\n",
            "      Successfully uninstalled torchtext-0.14.0\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 1.2.1\n",
            "    Uninstalling albumentations-1.2.1:\n",
            "      Successfully uninstalled albumentations-1.2.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 0.13.0+cu116 requires torch==1.13.0, but you have torch 1.12.1 which is incompatible.\n",
            "grpcio-status 1.48.2 requires grpcio>=1.48.2, but you have grpcio 1.43.0 which is incompatible.\n",
            "google-cloud-bigquery 3.3.6 requires grpcio<2.0dev,>=1.47.0, but you have grpcio 1.43.0 which is incompatible.\u001b[0m\n",
            "Successfully installed Autogluon-0.6.1 Pillow-9.3.0 accelerate-0.13.2 albumentations-1.1.0 antlr4-python3-runtime-4.8 autocfg-0.0.8 autogluon.common-0.6.1 autogluon.core-0.6.1 autogluon.features-0.6.1 autogluon.multimodal-0.6.1 autogluon.tabular-0.6.1 autogluon.text-0.6.1 autogluon.timeseries-0.6.1 autogluon.vision-0.6.1 boto3-1.26.29 botocore-1.29.29 catboost-1.1.1 colorama-0.4.6 commonmark-0.9.1 dask-2021.11.2 datasets-2.7.1 deprecated-1.2.13 distlib-0.3.6 distributed-2021.11.2 evaluate-0.3.0 fairscale-0.4.6 gluoncv-0.10.5.post0 gluonts-0.11.5 grpcio-1.43.0 huggingface-hub-0.11.1 hyperopt-0.2.7 jmespath-1.0.1 lightgbm-3.3.3 model-index-0.1.11 multiprocess-0.70.14 nlpaug-1.1.10 nptyping-1.4.4 omegaconf-2.1.2 openmim-0.2.1 ordered-set-4.1.0 pmdarima-1.8.5 portalocker-2.6.0 psutil-5.8.0 py4j-0.10.9.7 pyDeprecate-0.3.2 pytorch-lightning-1.7.7 pytorch-metric-learning-1.3.2 ray-2.0.1 responses-0.18.0 rich-12.6.0 s3transfer-0.6.0 scikit-image-0.19.3 sentencepiece-0.1.97 seqeval-1.2.2 sktime-0.13.4 statsmodels-0.13.5 tbats-1.1.2 tensorboardX-2.5.1 timm-0.6.12 tokenizers-0.13.2 torch-1.12.1 torchmetrics-0.8.2 torchtext-0.13.1 torchvision-0.13.1 transformers-4.23.1 typish-1.9.3 urllib3-1.25.11 virtualenv-20.17.1 xgboost-1.7.2 xxhash-3.1.0 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "psutil",
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install Autogluon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ZeiWzY8LnJZ7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "from scipy.signal import butter, lfilter\n",
        "from filterpy.kalman import KalmanFilter\n",
        "from filterpy.common import Q_discrete_white_noise\n",
        "import itertools\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# V1"
      ],
      "metadata": {
        "id": "WEVzcn8R0bOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/감귤/train.csv')\n",
        "test_x = pd.read_csv('/content/drive/MyDrive/감귤/test.csv')"
      ],
      "metadata": {
        "id": "JDdXovQiwSc9"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop(['ID'],axis = 1, inplace=True)\n",
        "test_x.drop(['ID'],axis = 1, inplace=True)"
      ],
      "metadata": {
        "id": "DYEDlwvPwSUC"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop(train.filter(regex = '엽록소').columns, axis = 1, inplace=True)\n",
        "test_x.drop(test_x.filter(regex = '엽록소').columns, axis = 1, inplace=True)"
      ],
      "metadata": {
        "id": "2AW4zttbwVnu"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['newsoon_ju'] = 0\n",
        "train['newsoon_ju'][train['2022-09-01 새순'] < 3] = 0.0213\n",
        "train['newsoon_ju'][(train['2022-09-01 새순'] >= 3) & (train['2022-09-01 새순'] < 3.5)] = 0.0275\n",
        "train['newsoon_ju'][(train['2022-09-01 새순'] >= 3.5) & (train['2022-09-01 새순'] < 4)] = 0.0335\n",
        "train['newsoon_ju'][(train['2022-09-01 새순'] >= 4) & (train['2022-09-01 새순'] < 4.5)] = 0.0395\n",
        "train['newsoon_ju'][train['2022-09-01 새순'] >= 4.5] = 0.0461\n",
        "\n",
        "\n",
        "test_x['newsoon_ju'] = 0\n",
        "test_x['newsoon_ju'][test_x['2022-09-01 새순'] < 3] = 0.0213\n",
        "test_x['newsoon_ju'][(test_x['2022-09-01 새순'] >= 3) & (test_x['2022-09-01 새순'] < 3.5)] = 0.0275\n",
        "test_x['newsoon_ju'][(test_x['2022-09-01 새순'] >= 3.5) & (test_x['2022-09-01 새순'] < 4)] = 0.0335\n",
        "test_x['newsoon_ju'][(test_x['2022-09-01 새순'] >= 4) & (test_x['2022-09-01 새순'] < 4.5)] = 0.0395\n",
        "test_x['newsoon_ju'][test_x['2022-09-01 새순'] >= 4.5] = 0.0461\n",
        "test_x['newsoon_ju']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHJByJeQwWX2",
        "outputId": "daeb97c5-be32-4994-f799-89ee83929c5b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-c911370097a6>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train['newsoon_ju'][train['2022-09-01 새순'] < 3] = 0.0213\n",
            "<ipython-input-33-c911370097a6>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train['newsoon_ju'][(train['2022-09-01 새순'] >= 3) & (train['2022-09-01 새순'] < 3.5)] = 0.0275\n",
            "<ipython-input-33-c911370097a6>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train['newsoon_ju'][(train['2022-09-01 새순'] >= 3.5) & (train['2022-09-01 새순'] < 4)] = 0.0335\n",
            "<ipython-input-33-c911370097a6>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train['newsoon_ju'][(train['2022-09-01 새순'] >= 4) & (train['2022-09-01 새순'] < 4.5)] = 0.0395\n",
            "<ipython-input-33-c911370097a6>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train['newsoon_ju'][train['2022-09-01 새순'] >= 4.5] = 0.0461\n",
            "<ipython-input-33-c911370097a6>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_x['newsoon_ju'][test_x['2022-09-01 새순'] < 3] = 0.0213\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0.0395\n",
              "1       0.0213\n",
              "2       0.0461\n",
              "3       0.0335\n",
              "4       0.0213\n",
              "         ...  \n",
              "2203    0.0213\n",
              "2204    0.0395\n",
              "2205    0.0335\n",
              "2206    0.0461\n",
              "2207    0.0461\n",
              "Name: newsoon_ju, Length: 2208, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_soon_tr = train.filter(regex = '새순')\n",
        "new_soon_tr = new_soon_tr[sorted(new_soon_tr.columns)]\n",
        "for i in range(len(new_soon_tr)):\n",
        "  for j in range(len(new_soon_tr.columns) - 1):\n",
        "    if(new_soon_tr.iloc[i,j] < new_soon_tr.iloc[i,j+1]):\n",
        "      new_soon_tr.iloc[i,j+1] = new_soon_tr.iloc[i,j]\n",
        "    if((new_soon_tr.iloc[i,j] == new_soon_tr.iloc[i,j+1]) | (new_soon_tr.iloc[i,j+1] == 0)):\n",
        "      new_soon_tr.iloc[i,j+1] = new_soon_tr.iloc[i,j] - train.iloc[i,-1]\n",
        "new_soon_tr[new_soon_tr < 0] = 0\n",
        "new_soon_tr\n",
        "\n",
        "\n",
        "new_soon_te = test_x.filter(regex = '새순')\n",
        "for i in range(len(new_soon_te)):\n",
        "  for j in range(len(new_soon_te.columns) - 1):\n",
        "    if(new_soon_te.iloc[i,j] < new_soon_te.iloc[i,j+1]): \n",
        "      new_soon_te.iloc[i,j+1] = new_soon_te.iloc[i,j]\n",
        "    if((new_soon_te.iloc[i,j] == new_soon_te.iloc[i,j+1]) | (new_soon_te.iloc[i,j+1] == 0)):\n",
        "      new_soon_te.iloc[i,j+1] = new_soon_te.iloc[i,j] - test_x.iloc[i,-1]\n",
        "new_soon_te[new_soon_te < 0] = 0\n",
        "new_soon_te"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        },
        "id": "G_bsLVwiwZLR",
        "outputId": "a448a29c-6af9-4134-a8fb-6a979335cf7d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_block(indexer, value, name)\n",
            "/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:723: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value, self.name)\n",
            "<ipython-input-34-fc3935f9c134>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  new_soon_te[new_soon_te < 0] = 0\n",
            "/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:3718: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._where(-key, value, inplace=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      2022-09-01 새순  2022-09-02 새순  2022-09-03 새순  2022-09-04 새순  \\\n",
              "0               4.3         4.2000         4.1605         4.1000   \n",
              "1               2.5         2.4787         2.4574         2.4361   \n",
              "2               4.7         4.6539         4.6000         4.5539   \n",
              "3               3.6         3.5665         3.5330         3.4995   \n",
              "4               2.7         2.6787         2.6574         2.6361   \n",
              "...             ...            ...            ...            ...   \n",
              "2203            2.5         2.4787         2.4000         2.3787   \n",
              "2204            4.1         4.0605         4.0210         4.0000   \n",
              "2205            3.8         3.7665         3.7330         3.7000   \n",
              "2206            4.5         4.4000         4.3539         4.3000   \n",
              "2207            4.9         4.8000         4.7539         4.7000   \n",
              "\n",
              "      2022-09-05 새순  2022-09-06 새순  2022-09-07 새순  2022-09-08 새순  \\\n",
              "0            4.0605         4.0210         4.0000         3.9605   \n",
              "1            2.4148         2.4000         2.3787         2.3574   \n",
              "2            4.5000         4.4539         4.4000         4.3539   \n",
              "3            3.4660         3.4325         3.4000         3.3665   \n",
              "4            2.6000         2.5787         2.5574         2.5361   \n",
              "...             ...            ...            ...            ...   \n",
              "2203         2.3574         2.3361         2.3000         2.2787   \n",
              "2204         3.9605         3.9000         3.8605         3.8000   \n",
              "2205         3.6665         3.6330         3.6000         3.5665   \n",
              "2206         4.2539         4.2000         4.1539         4.1078   \n",
              "2207         4.6539         4.6000         4.5539         4.5000   \n",
              "\n",
              "      2022-09-09 새순  2022-09-10 새순  ...  2022-11-19 새순  2022-11-20 새순  \\\n",
              "0            3.9000         3.8605  ...         0.8000         0.7605   \n",
              "1            2.3361         2.3148  ...         0.7787         0.7574   \n",
              "2            4.3000         4.2539  ...         0.8539         0.8000   \n",
              "3            3.3330         3.3000  ...         0.8000         0.7665   \n",
              "4            2.5000         2.4787  ...         0.8361         0.8000   \n",
              "...             ...            ...  ...            ...            ...   \n",
              "2203         2.2574         2.2361  ...         0.7509         0.7296   \n",
              "2204         3.7605         3.7000  ...         0.8000         0.7605   \n",
              "2205         3.5000         3.4665  ...         0.9000         0.8665   \n",
              "2206         4.1000         4.0539  ...         0.8539         0.8000   \n",
              "2207         4.4539         4.4000  ...         0.8000         0.7539   \n",
              "\n",
              "      2022-11-21 새순  2022-11-22 새순  2022-11-23 새순  2022-11-24 새순  \\\n",
              "0            0.7000         0.6605         0.6000         0.5605   \n",
              "1            0.7361         0.7148         0.7000         0.6787   \n",
              "2            0.7539         0.7000         0.6539         0.6000   \n",
              "3            0.7000         0.6665         0.6330         0.6000   \n",
              "4            0.7787         0.7574         0.7361         0.7000   \n",
              "...             ...            ...            ...            ...   \n",
              "2203         0.7083         0.7000         0.6787         0.6574   \n",
              "2204         0.7000         0.6605         0.6000         0.5605   \n",
              "2205         0.8000         0.7665         0.7330         0.7000   \n",
              "2206         0.7539         0.7000         0.6539         0.6078   \n",
              "2207         0.7000         0.6539         0.6000         0.5539   \n",
              "\n",
              "      2022-11-25 새순  2022-11-26 새순  2022-11-27 새순  2022-11-28 새순  \n",
              "0            0.5210         0.5000         0.4605         0.4210  \n",
              "1            0.6574         0.6361         0.6000         0.5787  \n",
              "2            0.5539         0.5000         0.4539         0.4078  \n",
              "3            0.5665         0.5330         0.5000         0.4665  \n",
              "4            0.6787         0.6574         0.6361         0.6148  \n",
              "...             ...            ...            ...            ...  \n",
              "2203         0.6361         0.6000         0.5787         0.5574  \n",
              "2204         0.5210         0.5000         0.4605         0.4210  \n",
              "2205         0.6665         0.6330         0.6000         0.5665  \n",
              "2206         0.6000         0.5000         0.4539         0.4078  \n",
              "2207         0.5000         0.4539         0.4078         0.3617  \n",
              "\n",
              "[2208 rows x 89 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad0aecc5-e013-4e03-95d1-3d848e8c928c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2022-09-01 새순</th>\n",
              "      <th>2022-09-02 새순</th>\n",
              "      <th>2022-09-03 새순</th>\n",
              "      <th>2022-09-04 새순</th>\n",
              "      <th>2022-09-05 새순</th>\n",
              "      <th>2022-09-06 새순</th>\n",
              "      <th>2022-09-07 새순</th>\n",
              "      <th>2022-09-08 새순</th>\n",
              "      <th>2022-09-09 새순</th>\n",
              "      <th>2022-09-10 새순</th>\n",
              "      <th>...</th>\n",
              "      <th>2022-11-19 새순</th>\n",
              "      <th>2022-11-20 새순</th>\n",
              "      <th>2022-11-21 새순</th>\n",
              "      <th>2022-11-22 새순</th>\n",
              "      <th>2022-11-23 새순</th>\n",
              "      <th>2022-11-24 새순</th>\n",
              "      <th>2022-11-25 새순</th>\n",
              "      <th>2022-11-26 새순</th>\n",
              "      <th>2022-11-27 새순</th>\n",
              "      <th>2022-11-28 새순</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.3</td>\n",
              "      <td>4.2000</td>\n",
              "      <td>4.1605</td>\n",
              "      <td>4.1000</td>\n",
              "      <td>4.0605</td>\n",
              "      <td>4.0210</td>\n",
              "      <td>4.0000</td>\n",
              "      <td>3.9605</td>\n",
              "      <td>3.9000</td>\n",
              "      <td>3.8605</td>\n",
              "      <td>...</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.7605</td>\n",
              "      <td>0.7000</td>\n",
              "      <td>0.6605</td>\n",
              "      <td>0.6000</td>\n",
              "      <td>0.5605</td>\n",
              "      <td>0.5210</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.4605</td>\n",
              "      <td>0.4210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.5</td>\n",
              "      <td>2.4787</td>\n",
              "      <td>2.4574</td>\n",
              "      <td>2.4361</td>\n",
              "      <td>2.4148</td>\n",
              "      <td>2.4000</td>\n",
              "      <td>2.3787</td>\n",
              "      <td>2.3574</td>\n",
              "      <td>2.3361</td>\n",
              "      <td>2.3148</td>\n",
              "      <td>...</td>\n",
              "      <td>0.7787</td>\n",
              "      <td>0.7574</td>\n",
              "      <td>0.7361</td>\n",
              "      <td>0.7148</td>\n",
              "      <td>0.7000</td>\n",
              "      <td>0.6787</td>\n",
              "      <td>0.6574</td>\n",
              "      <td>0.6361</td>\n",
              "      <td>0.6000</td>\n",
              "      <td>0.5787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>4.6539</td>\n",
              "      <td>4.6000</td>\n",
              "      <td>4.5539</td>\n",
              "      <td>4.5000</td>\n",
              "      <td>4.4539</td>\n",
              "      <td>4.4000</td>\n",
              "      <td>4.3539</td>\n",
              "      <td>4.3000</td>\n",
              "      <td>4.2539</td>\n",
              "      <td>...</td>\n",
              "      <td>0.8539</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.7539</td>\n",
              "      <td>0.7000</td>\n",
              "      <td>0.6539</td>\n",
              "      <td>0.6000</td>\n",
              "      <td>0.5539</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.4539</td>\n",
              "      <td>0.4078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.6</td>\n",
              "      <td>3.5665</td>\n",
              "      <td>3.5330</td>\n",
              "      <td>3.4995</td>\n",
              "      <td>3.4660</td>\n",
              "      <td>3.4325</td>\n",
              "      <td>3.4000</td>\n",
              "      <td>3.3665</td>\n",
              "      <td>3.3330</td>\n",
              "      <td>3.3000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.7665</td>\n",
              "      <td>0.7000</td>\n",
              "      <td>0.6665</td>\n",
              "      <td>0.6330</td>\n",
              "      <td>0.6000</td>\n",
              "      <td>0.5665</td>\n",
              "      <td>0.5330</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.4665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.7</td>\n",
              "      <td>2.6787</td>\n",
              "      <td>2.6574</td>\n",
              "      <td>2.6361</td>\n",
              "      <td>2.6000</td>\n",
              "      <td>2.5787</td>\n",
              "      <td>2.5574</td>\n",
              "      <td>2.5361</td>\n",
              "      <td>2.5000</td>\n",
              "      <td>2.4787</td>\n",
              "      <td>...</td>\n",
              "      <td>0.8361</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.7787</td>\n",
              "      <td>0.7574</td>\n",
              "      <td>0.7361</td>\n",
              "      <td>0.7000</td>\n",
              "      <td>0.6787</td>\n",
              "      <td>0.6574</td>\n",
              "      <td>0.6361</td>\n",
              "      <td>0.6148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2203</th>\n",
              "      <td>2.5</td>\n",
              "      <td>2.4787</td>\n",
              "      <td>2.4000</td>\n",
              "      <td>2.3787</td>\n",
              "      <td>2.3574</td>\n",
              "      <td>2.3361</td>\n",
              "      <td>2.3000</td>\n",
              "      <td>2.2787</td>\n",
              "      <td>2.2574</td>\n",
              "      <td>2.2361</td>\n",
              "      <td>...</td>\n",
              "      <td>0.7509</td>\n",
              "      <td>0.7296</td>\n",
              "      <td>0.7083</td>\n",
              "      <td>0.7000</td>\n",
              "      <td>0.6787</td>\n",
              "      <td>0.6574</td>\n",
              "      <td>0.6361</td>\n",
              "      <td>0.6000</td>\n",
              "      <td>0.5787</td>\n",
              "      <td>0.5574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2204</th>\n",
              "      <td>4.1</td>\n",
              "      <td>4.0605</td>\n",
              "      <td>4.0210</td>\n",
              "      <td>4.0000</td>\n",
              "      <td>3.9605</td>\n",
              "      <td>3.9000</td>\n",
              "      <td>3.8605</td>\n",
              "      <td>3.8000</td>\n",
              "      <td>3.7605</td>\n",
              "      <td>3.7000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.7605</td>\n",
              "      <td>0.7000</td>\n",
              "      <td>0.6605</td>\n",
              "      <td>0.6000</td>\n",
              "      <td>0.5605</td>\n",
              "      <td>0.5210</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.4605</td>\n",
              "      <td>0.4210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2205</th>\n",
              "      <td>3.8</td>\n",
              "      <td>3.7665</td>\n",
              "      <td>3.7330</td>\n",
              "      <td>3.7000</td>\n",
              "      <td>3.6665</td>\n",
              "      <td>3.6330</td>\n",
              "      <td>3.6000</td>\n",
              "      <td>3.5665</td>\n",
              "      <td>3.5000</td>\n",
              "      <td>3.4665</td>\n",
              "      <td>...</td>\n",
              "      <td>0.9000</td>\n",
              "      <td>0.8665</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.7665</td>\n",
              "      <td>0.7330</td>\n",
              "      <td>0.7000</td>\n",
              "      <td>0.6665</td>\n",
              "      <td>0.6330</td>\n",
              "      <td>0.6000</td>\n",
              "      <td>0.5665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2206</th>\n",
              "      <td>4.5</td>\n",
              "      <td>4.4000</td>\n",
              "      <td>4.3539</td>\n",
              "      <td>4.3000</td>\n",
              "      <td>4.2539</td>\n",
              "      <td>4.2000</td>\n",
              "      <td>4.1539</td>\n",
              "      <td>4.1078</td>\n",
              "      <td>4.1000</td>\n",
              "      <td>4.0539</td>\n",
              "      <td>...</td>\n",
              "      <td>0.8539</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.7539</td>\n",
              "      <td>0.7000</td>\n",
              "      <td>0.6539</td>\n",
              "      <td>0.6078</td>\n",
              "      <td>0.6000</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.4539</td>\n",
              "      <td>0.4078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2207</th>\n",
              "      <td>4.9</td>\n",
              "      <td>4.8000</td>\n",
              "      <td>4.7539</td>\n",
              "      <td>4.7000</td>\n",
              "      <td>4.6539</td>\n",
              "      <td>4.6000</td>\n",
              "      <td>4.5539</td>\n",
              "      <td>4.5000</td>\n",
              "      <td>4.4539</td>\n",
              "      <td>4.4000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.7539</td>\n",
              "      <td>0.7000</td>\n",
              "      <td>0.6539</td>\n",
              "      <td>0.6000</td>\n",
              "      <td>0.5539</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.4539</td>\n",
              "      <td>0.4078</td>\n",
              "      <td>0.3617</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2208 rows × 89 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad0aecc5-e013-4e03-95d1-3d848e8c928c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ad0aecc5-e013-4e03-95d1-3d848e8c928c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ad0aecc5-e013-4e03-95d1-3d848e8c928c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_soon_tr = new_soon_tr.add_suffix('_new')\n",
        "new_soon_te = new_soon_te.add_suffix('_new')\n",
        "train = pd.concat([train,new_soon_tr],axis=1)\n",
        "\n",
        "test_x = pd.concat([test_x,new_soon_te],axis=1)"
      ],
      "metadata": {
        "id": "UKvvVAtRweLK"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = TabularDataset(train)\n",
        "test_data = TabularDataset(test_x)\n",
        "print(\"==================Tabular_complete========================\")\n",
        "print(\"==================Tabular_complete========================\")\n",
        "print(\"==================Tabular_complete========================\")\n",
        "print(\"==================Tabular_complete========================\")\n",
        "print(\"==================Tabular_complete========================\")\n",
        "predictor = TabularPredictor(label='착과량(int)',  eval_metric='mean_absolute_error').fit(train_data, presets='high_quality',  ag_args_fit={'num_gpus': 0})\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "y_pred = predictor.predict(test_data)\n",
        "print(\"==================predictor_complete========================\")\n",
        "print(\"==================predictor_complete========================\")\n",
        "print(\"==================predictor_complete========================\")\n",
        "print(\"==================predictor_complete========================\")\n",
        "print(\"==================predictor_complete========================\")\n",
        "y_pred = pd.DataFrame(y_pred, columns=['착과량(int)'])\n",
        "V1 = pd.read_csv('/content/drive/MyDrive/감귤/sample_submission.csv')\n",
        "V1['착과량(int)'] = y_pred\n",
        "V1.to_csv('V1.csv', index=False)\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpYciugewmLW",
        "outputId": "28fc8d93-5182-4dbb-fc20-252987aa901f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20221214_133301/\"\n",
            "Presets specified: ['high_quality']\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20221214_133301/\"\n",
            "AutoGluon Version:  0.6.1\n",
            "Python Version:     3.8.16\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Fri Aug 26 08:44:51 UTC 2022\n",
            "Train Data Rows:    2207\n",
            "Train Data Columns: 183\n",
            "Label Column: 착과량(int)\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == int and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (799, 1, 406.22247, 218.9783)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11864.55 MB\n",
            "\tTrain Data (Original)  Memory Usage: 3.23 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================Tabular_complete========================\n",
            "==================Tabular_complete========================\n",
            "==================Tabular_complete========================\n",
            "==================Tabular_complete========================\n",
            "==================Tabular_complete========================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 183 | ['수고(m)', '수관폭1(min)', '수관폭2(max)', '수관폭평균', '2022-09-01 새순', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 183 | ['수고(m)', '수관폭1(min)', '수관폭2(max)', '수관폭평균', '2022-09-01 새순', ...]\n",
            "\t0.2s = Fit runtime\n",
            "\t183 features in original data used to generate 183 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 3.23 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.31s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
            "\t-122.7262\t = Validation score   (-mean_absolute_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.3s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ...\n",
            "\t-117.3547\t = Validation score   (-mean_absolute_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ...\n",
            "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 500, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: LightGBM_BAG_L1 ...\n",
            "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 500, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: RandomForestMSE_BAG_L1 ...\n",
            "\t-31.0757\t = Validation score   (-mean_absolute_error)\n",
            "\t22.14s\t = Training   runtime\n",
            "\t0.3s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ...\n",
            "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 500, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
            "\t-30.9887\t = Validation score   (-mean_absolute_error)\n",
            "\t9.6s\t = Training   runtime\n",
            "\t0.29s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
            "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 500, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: XGBoost_BAG_L1 ...\n",
            "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 500, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
            "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 500, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: LightGBMLarge_BAG_L1 ...\n",
            "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 500, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t-30.9046\t = Validation score   (-mean_absolute_error)\n",
            "\t0.14s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 9 L2 models ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ...\n",
            "\tWarning: Exception caused LightGBMXT_BAG_L2 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 500, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: LightGBM_BAG_L2 ...\n",
            "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 500, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: RandomForestMSE_BAG_L2 ...\n",
            "\t-29.7038\t = Validation score   (-mean_absolute_error)\n",
            "\t23.77s\t = Training   runtime\n",
            "\t0.29s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L2 ...\n",
            "\tWarning: Exception caused CatBoost_BAG_L2 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 500, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
            "\t-29.4523\t = Validation score   (-mean_absolute_error)\n",
            "\t9.94s\t = Training   runtime\n",
            "\t0.29s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
            "\tWarning: Exception caused NeuralNetFastAI_BAG_L2 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 500, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: XGBoost_BAG_L2 ...\n",
            "\tWarning: Exception caused XGBoost_BAG_L2 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 500, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
            "\tWarning: Exception caused NeuralNetTorch_BAG_L2 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 500, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: LightGBMLarge_BAG_L2 ...\n",
            "\tWarning: Exception caused LightGBMLarge_BAG_L2 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 500, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: WeightedEnsemble_L3 ...\n",
            "\t-29.3825\t = Validation score   (-mean_absolute_error)\n",
            "\t0.08s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 69.82s ... Best model: \"WeightedEnsemble_L3\"\n",
            "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.3s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t22.14s\t = Training   runtime\n",
            "\t0.3s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t9.6s\t = Training   runtime\n",
            "\t0.29s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
            "\t0.14s\t = Training   runtime\n",
            "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
            "\t23.77s\t = Training   runtime\n",
            "\t0.29s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
            "\t9.94s\t = Training   runtime\n",
            "\t0.29s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
            "\t0.08s\t = Training   runtime\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221214_133301/\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================learning_complete========================\n",
            "==================learning_complete========================\n",
            "==================learning_complete========================\n",
            "==================learning_complete========================\n",
            "==================learning_complete========================\n",
            "==================learning_complete========================\n",
            "==================predictor_complete========================\n",
            "==================predictor_complete========================\n",
            "==================predictor_complete========================\n",
            "==================predictor_complete========================\n",
            "==================predictor_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.to_csv('V1train.csv',index=False)"
      ],
      "metadata": {
        "id": "NITXuv8hyroM"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# V2"
      ],
      "metadata": {
        "id": "3vNpnQatwAEd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "08iV2btOnXvj"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/감귤/train.csv')\n",
        "test_x = pd.read_csv('/content/drive/MyDrive/감귤/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "o2ZHVZzOofek"
      },
      "outputs": [],
      "source": [
        "train.drop(['ID'],axis = 1, inplace=True)\n",
        "test_x.drop(['ID'],axis = 1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop(train.filter(regex = '엽록소').columns, axis = 1, inplace=True)\n",
        "test_x.drop(test_x.filter(regex = '엽록소').columns, axis = 1, inplace=True)"
      ],
      "metadata": {
        "id": "r_LA7KyMr5RZ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LPF(series, low, order=1):\n",
        "    b, a = butter(\n",
        "                  N = order,\n",
        "                  Wn = low,\n",
        "                  btype = 'low',\n",
        "                  )\n",
        "    lpf_series = lfilter(b, a, series)\n",
        "    \n",
        "    return lpf_series"
      ],
      "metadata": {
        "id": "b_q8yY2_egkX"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_lpf = train.filter(regex='새순')\n",
        "train_lpf = train_lpf.T\n",
        "train_lpf = train_lpf.add_suffix('_lpf')\n",
        "train_merge = LPF(train_lpf,0.1,1)\n",
        "train_merge = train_merge.T\n",
        "train_merge = pd.DataFrame(train_merge)\n",
        "train_merge = train_merge.add_suffix('_lpf')\n",
        "train = pd.concat([train, train_merge],axis=1)\n",
        "\n",
        "\n",
        "test_lpf = test_x.filter(regex='새순')\n",
        "test_lpf = test_lpf.T\n",
        "test_lpf = test_lpf.add_suffix('_lpf')\n",
        "test_merge = LPF(test_lpf,0.1,1)\n",
        "test_merge = test_merge.T\n",
        "test_merge = pd.DataFrame(test_merge)\n",
        "test_merge = test_merge.add_suffix('_lpf')\n",
        "test_x = pd.concat([test_x, test_merge],axis=1)"
      ],
      "metadata": {
        "id": "57ltQB-Uem4I"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKZZZQJrqiYt",
        "outputId": "d97f5539-e713-47d0-f163-eb1ac434f98e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20221214_133414/\"\n",
            "Presets specified: ['high_quality']\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20221214_133414/\"\n",
            "AutoGluon Version:  0.6.1\n",
            "Python Version:     3.8.16\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Fri Aug 26 08:44:51 UTC 2022\n",
            "Train Data Rows:    2207\n",
            "Train Data Columns: 182\n",
            "Label Column: 착과량(int)\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == int and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (799, 1, 406.22247, 218.9783)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11890.81 MB\n",
            "\tTrain Data (Original)  Memory Usage: 3.21 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================Tabular_complete========================\n",
            "==================Tabular_complete========================\n",
            "==================Tabular_complete========================\n",
            "==================Tabular_complete========================\n",
            "==================Tabular_complete========================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 182 | ['수고(m)', '수관폭1(min)', '수관폭2(max)', '수관폭평균', '2022-09-01 새순', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 182 | ['수고(m)', '수관폭1(min)', '수관폭2(max)', '수관폭평균', '2022-09-01 새순', ...]\n",
            "\t0.2s = Fit runtime\n",
            "\t182 features in original data used to generate 182 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 3.21 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.33s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
            "\t-148.724\t = Validation score   (-mean_absolute_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ...\n",
            "\t-143.3443\t = Validation score   (-mean_absolute_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.3s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ...\n",
            "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 500, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: LightGBM_BAG_L1 ...\n",
            "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 500, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: RandomForestMSE_BAG_L1 ...\n",
            "\t-30.4296\t = Validation score   (-mean_absolute_error)\n",
            "\t37.38s\t = Training   runtime\n",
            "\t0.28s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ...\n",
            "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 500, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
            "\t-30.5205\t = Validation score   (-mean_absolute_error)\n",
            "\t10.3s\t = Training   runtime\n",
            "\t0.29s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
            "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 500, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: XGBoost_BAG_L1 ...\n",
            "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 500, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
            "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 500, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: LightGBMLarge_BAG_L1 ...\n",
            "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 500, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t-30.3273\t = Validation score   (-mean_absolute_error)\n",
            "\t0.14s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 9 L2 models ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ...\n",
            "\tWarning: Exception caused LightGBMXT_BAG_L2 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 500, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: LightGBM_BAG_L2 ...\n",
            "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 500, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: RandomForestMSE_BAG_L2 ...\n",
            "\t-30.2752\t = Validation score   (-mean_absolute_error)\n",
            "\t43.87s\t = Training   runtime\n",
            "\t0.29s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L2 ...\n",
            "\tWarning: Exception caused CatBoost_BAG_L2 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 500, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
            "\t-30.1416\t = Validation score   (-mean_absolute_error)\n",
            "\t10.65s\t = Training   runtime\n",
            "\t0.29s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
            "\tWarning: Exception caused NeuralNetFastAI_BAG_L2 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 500, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: XGBoost_BAG_L2 ...\n",
            "\tWarning: Exception caused XGBoost_BAG_L2 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 500, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
            "\tWarning: Exception caused NeuralNetTorch_BAG_L2 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 500, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: LightGBMLarge_BAG_L2 ...\n",
            "\tWarning: Exception caused LightGBMLarge_BAG_L2 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 236, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 500, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: WeightedEnsemble_L3 ...\n",
            "\t-30.0643\t = Validation score   (-mean_absolute_error)\n",
            "\t0.1s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 107.39s ... Best model: \"WeightedEnsemble_L3\"\n",
            "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.3s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t37.38s\t = Training   runtime\n",
            "\t0.28s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t10.3s\t = Training   runtime\n",
            "\t0.29s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
            "\t0.14s\t = Training   runtime\n",
            "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
            "\t43.87s\t = Training   runtime\n",
            "\t0.29s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
            "\t10.65s\t = Training   runtime\n",
            "\t0.29s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
            "\t0.1s\t = Training   runtime\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221214_133414/\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================learning_complete========================\n",
            "==================learning_complete========================\n",
            "==================learning_complete========================\n",
            "==================learning_complete========================\n",
            "==================learning_complete========================\n",
            "==================learning_complete========================\n",
            "==================predictor_complete========================\n",
            "==================predictor_complete========================\n",
            "==================predictor_complete========================\n",
            "==================predictor_complete========================\n",
            "==================predictor_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "\n",
        "train_data = TabularDataset(train)\n",
        "test_data = TabularDataset(test_x)\n",
        "print(\"==================Tabular_complete========================\")\n",
        "print(\"==================Tabular_complete========================\")\n",
        "print(\"==================Tabular_complete========================\")\n",
        "print(\"==================Tabular_complete========================\")\n",
        "print(\"==================Tabular_complete========================\")\n",
        "predictor = TabularPredictor(label='착과량(int)',  eval_metric='mean_absolute_error').fit(train_data, presets='high_quality',  ag_args_fit={'num_gpus': 0})\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "y_pred = predictor.predict(test_data)\n",
        "print(\"==================predictor_complete========================\")\n",
        "print(\"==================predictor_complete========================\")\n",
        "print(\"==================predictor_complete========================\")\n",
        "print(\"==================predictor_complete========================\")\n",
        "print(\"==================predictor_complete========================\")\n",
        "y_pred = pd.DataFrame(y_pred, columns=['착과량(int)'])\n",
        "V2 = pd.read_csv('/content/drive/MyDrive/감귤/sample_submission.csv')\n",
        "V2['착과량(int)'] = y_pred\n",
        "V2.to_csv('V2.csv', index=False)\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.to_csv('V2train.csv',index=False)"
      ],
      "metadata": {
        "id": "210b3F6lyn01"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ens"
      ],
      "metadata": {
        "id": "uOX49BDvwpQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ens = pd.read_csv('/content/drive/MyDrive/감귤/sample_submission.csv')\n",
        "ens['착과량(int)'] = (V1['착과량(int)'] + V2['착과량(int)']) / 2\n",
        "ens['착과량(int)'] = round(ens['착과량(int)'])\n",
        "ens.to_csv('submit.csv',index=False)"
      ],
      "metadata": {
        "id": "x2WcW3vgwqMH"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7hpRrHX71LjQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}